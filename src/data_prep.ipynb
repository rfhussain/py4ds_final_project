{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import utils2\n",
    "sales_util = utils2.SalesUtils('')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_path = '../data/'\n",
    "working_path = '../working/'\n",
    "d_parser = lambda x: pd.datetime.strptime(x,'%d.%m.%Y')\n",
    "df_sales           = pd.read_csv(os.path.join(input_path, 'sales_train.csv'), parse_dates =[\"date\"],date_parser=d_parser)\n",
    "df_items           = pd.read_csv(os.path.join(input_path, 'items.csv'))\n",
    "df_item_categories = pd.read_csv(os.path.join(input_path, 'item_categories.csv'))\n",
    "df_shops           = pd.read_csv(os.path.join(input_path, 'shops.csv'))\n",
    "df_test            = pd.read_csv(os.path.join(input_path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_cast_dataframe(df_matrix):\n",
    "    df_matrix['date_block_num'] = df_matrix['date_block_num'].astype('int8')\n",
    "    df_matrix['shop_id'] = df_matrix['shop_id'].astype('int8')\n",
    "    df_matrix['item_id'] = df_matrix['item_id'].astype('int16')\n",
    "    df_matrix['target'] = df_matrix['target'].astype('float16')\n",
    "    df_matrix['target_shop'] = df_matrix['target_shop'].astype('float16')\n",
    "    df_matrix['target_item'] = df_matrix['target_item'].astype('float16')\n",
    "    df_matrix['month'] = df_matrix['month'].astype('int8')\n",
    "    df_matrix['item_category_id'] = df_matrix['item_category_id'].astype('int8')\n",
    "    df_matrix['parent_cat_id'] = df_matrix['parent_cat_id'].astype('int8')\n",
    "    df_matrix['city_id'] = df_matrix['city_id'].astype('int8')\n",
    "    df_matrix['num_days'] = df_matrix['num_days'].astype('int8')\n",
    "    df_matrix['num_sun'] = df_matrix['num_sun'].astype('int8')\n",
    "    df_matrix['num_sat'] = df_matrix['num_sat'].astype('int8')\n",
    "    df_matrix['name_2'] = df_matrix['name_2'].astype('int16')\n",
    "    df_matrix['name_3'] = df_matrix['name_3'].astype('int16')\n",
    "\n",
    "    # getting the mean attributes\n",
    "    mean_enc_cols = [col for col in df_matrix.columns if 'mean' in str(col)]\n",
    "    for col in mean_enc_cols:\n",
    "        df_matrix[col] = df_matrix[col].astype('float16')\n",
    "\n",
    "    # getting the mean attributes\n",
    "    revenue_cols = [col for col in df_matrix.columns if 'revenue' in str(col)]\n",
    "    for col in revenue_cols:\n",
    "        df_matrix[col] = df_matrix[col].astype('float32')\n",
    "    return df_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Set Pipeine-1\n",
    "Cleaning, Imputation, Outliers, Merging, Features etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "############ DELETING OUTLIERS \n",
    "# deleting the quantities which are greater than 1001\n",
    "df_sales = df_sales[df_sales['item_cnt_day']<=1001]\n",
    "#any item_cnt_day which is less than 0 should be 0\n",
    "df_sales.loc[df_sales.item_cnt_day < 1,'item_cnt_day'] = 0 \n",
    "\n",
    "# values more than 55k could be outliers, so deleting all above 55k\n",
    "df_sales = df_sales[df_sales['item_price']<= 55000]\n",
    "\n",
    "#item price, should obviously not be less than 0 ... either it should be deleted or imputed.\n",
    "df_sales = df_sales[df_sales['item_price'] > 0]\n",
    "\n",
    "############ ADDING DATE ATTRIBUTES\n",
    "# Adding the date time attributes (like week day, month number, etc.)\n",
    "df_sales = sales_util.add_date_attributes(df_sales)\n",
    "\n",
    "############ REPLACING DUPLICATE SHOPS FROM SALES\n",
    "# based on the above, duplicating as follows\n",
    "df_sales['shop_id'].replace({0: 57, 1: 58, 11: 10, 40: 39}, inplace=True)\n",
    "\n",
    "############ REMOVING OUTDATED SHOPS FROM SALES\n",
    "outdated_shops = [0, 1, 8, 11, 13, 17, 23, 29, 30, 32, 33, 40, 43, 54]\n",
    "df_sales = df_sales[df_sales['shop_id'].isin(outdated_shops)==False]\n",
    "\n",
    "############ MERGING WITH THE SALES AND SHOPS AND ITEMS/ITEM_CATEGORIES\n",
    "df_sales = sales_util.merge_items_sales_n_shops(df_sales)\n",
    "\n",
    "############ CREATING THE MONTHLY REVENUE\n",
    "df_sales['revenue'] = df_sales['item_cnt_day'] * df_sales['item_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Pipeine-1\n",
    "Cleaning, Imputation, Outliers, Merging, Features etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 993 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#1. test data frame, adding date_block_num and month\n",
    "df_test['date_block_num'] = 34\n",
    "df_test['month'] = 11\n",
    "\n",
    "############ REPLACING DUPLICATE SHOPS FROM SALES\n",
    "# based on the above, duplicating as follows\n",
    "df_sales['shop_id'].replace({0: 57, 1: 58, 11: 10, 40: 39}, inplace=True)\n",
    "\n",
    "#2. merging, just like the sales\n",
    "df_test = sales_util.merge_items_sales_n_shops(df_test)\n",
    "\n",
    "############ REPLACING DUPLICATE CATEGORY\n",
    "# duplicate category id\n",
    "df_test['item_category_id'].replace({8: 80, 27: 74, 75: 76}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Set Pipeine-2\n",
    "Advanced feature generation, monthly grouping, merge with the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf956455b574b07972569fbee352847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a748f518997941ec9b24a0cb3dd68552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 17min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "############ DAYS IN A MONTH BY DATE_BLOCK_NUM\n",
    "# getting the number of days, and sundays by date_block_num\n",
    "days_counts = sales_util.get_days_count()\n",
    "\n",
    "############ MATRIX CONVERSION BY MONTH SHOP_ID X ITEM_ID for each DATE_BLOCK_NUM\n",
    "df_matrix = sales_util.get_matrix_by_block(df_sales)\n",
    "\n",
    "############ MERGING WITH THE SALES AND SHOPS AND ITEMS/ITEM_CATEGORIES\n",
    "'''\n",
    "This needs to be performed again, since many of the columns while converting \n",
    "to matrix will be ignored\n",
    "'''\n",
    "df_matrix = sales_util.merge_items_sales_n_shops(df_matrix)\n",
    "\n",
    "############ DELETE THE UNWANTED COLUMNS ONCE\n",
    "df_matrix.drop(['item_category_name','item_cat_en','parent_cat','city_name'], axis=1, inplace=True)\n",
    "df_test.drop(['item_category_name','item_cat_en','parent_cat','city_name'], axis=1, inplace=True)\n",
    "\n",
    "############ CONCATING BOTH TEST AND TRAIN(SALES)\n",
    "df_matrix = pd.concat([df_matrix, df_test], axis=0)\n",
    "df_matrix = df_matrix.drop(columns = ['ID'])\n",
    "df_matrix.fillna(0,inplace=True)\n",
    "\n",
    "############ JOIN THE NUM_DAYS\n",
    "df_matrix = df_matrix.merge(days_counts, how='inner')\n",
    "\n",
    "############ DOWN CASTING \n",
    "df_matrix = down_cast_dataframe(df_matrix)\n",
    "\n",
    "############ ADDING THE MEANS\n",
    "'''\n",
    "#adding the mean attributes\n",
    "\n",
    "1: expanding mean by shop id\n",
    "2: shop/item target mean\n",
    "3: item id target mean\n",
    "4: month target mean\n",
    "5: parent cat target mean\n",
    "6: item category target mean\n",
    "7: shop id target mean\n",
    "8: city id target mean\n",
    "9: shop_city target mean\n",
    "10: date_block_num target mean\n",
    "\n",
    "'''\n",
    "means_to_be_used = [1,2,3,4,5,6,7,8,9,10]\n",
    "df_matrix = sales_util.add_mean_features(df_matrix, means_to_be_used)\n",
    "df_matrix.fillna(0, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "############ DOWN CASTING \n",
    "df_matrix = down_cast_dataframe(df_matrix)\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "############ ADDING LAGS\n",
    "mean_enc_cols = [col for col in df_matrix.columns if 'mean' in str(col)]\n",
    "# removing the mean cols temporarily so that memory usage doesn't get high\n",
    "dftmp = df_matrix[mean_enc_cols + ['shop_id','item_id','date_block_num']]\n",
    "df_matrix.drop(mean_enc_cols,axis=1, inplace=True)\n",
    "shift_range = [1,2,3,4,12]\n",
    "# additional columns, not to be counted when calculating lags\n",
    "except_cols = ['num_days','num_sat','num_sun','name_2','name_3','city_id','parent_cat_id','item_category_id','month'] \n",
    "df_matrix = sales_util.add_lags(df_matrix, shift_range, except_cols)\n",
    "# adding back the mean cols again\n",
    "df_matrix = df_matrix.merge(dftmp, how='inner', on=['shop_id','item_id','date_block_num'])\n",
    "\n",
    "############ REMOVING THE DATA FROM BEFORE 2013 \n",
    "df_matrix = df_matrix[df_matrix.date_block_num > 3]\n",
    "\n",
    "############ SAVINTG THE DATA IN WORKING DIRECTORY\n",
    "df_matrix.to_csv(os.path.join(working_path, 'df_main_with_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
