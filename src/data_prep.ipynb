{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import utils2\n",
    "sales_util = utils2.SalesUtils('')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_path = '../data/'\n",
    "d_parser = lambda x: pd.datetime.strptime(x,'%d.%m.%Y')\n",
    "df_sales           = pd.read_csv(os.path.join(input_path, 'sales_train.csv'), parse_dates =[\"date\"],date_parser=d_parser)\n",
    "df_items           = pd.read_csv(os.path.join(input_path, 'items.csv'))\n",
    "df_item_categories = pd.read_csv(os.path.join(input_path, 'item_categories.csv'))\n",
    "df_shops           = pd.read_csv(os.path.join(input_path, 'shops.csv'))\n",
    "df_test            = pd.read_csv(os.path.join(input_path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Set Pipeine-1\n",
    "Cleaning, Imputation, Outliers, Merging, Features etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "############ DELETING OUTLIERS \n",
    "# deleting the quantities which are greater than 1001\n",
    "df_sales = df_sales[df_sales['item_cnt_day']<=1001]\n",
    "#any item_cnt_day which is less than 0 should be 0\n",
    "df_sales.loc[df_sales.item_cnt_day < 1,'item_cnt_day'] = 0 \n",
    "\n",
    "# values more than 55k could be outliers, so deleting all above 55k\n",
    "df_sales = df_sales[df_sales['item_price']<= 55000]\n",
    "\n",
    "#item price, should obviously not be less than 0 ... either it should be deleted or imputed.\n",
    "df_sales = df_sales[df_sales['item_price'] > 0]\n",
    "\n",
    "############ ADDING DATE ATTRIBUTES\n",
    "# Adding the date time attributes (like week day, month number, etc.)\n",
    "df_sales = sales_util.add_date_attributes(df_sales)\n",
    "\n",
    "############ REPLACING DUPLICATE SHOPS FROM SALES\n",
    "# based on the above, duplicating as follows\n",
    "df_sales['shop_id'].replace({0: 57, 1: 58, 11: 10, 40: 39}, inplace=True)\n",
    "\n",
    "############ REMOVING OUTDATED SHOPS FROM SALES\n",
    "outdated_shops = [0, 1, 8, 11, 13, 17, 23, 29, 30, 32, 33, 40, 43, 54]\n",
    "df_sales = df_sales[df_sales['shop_id'].isin(outdated_shops)==False]\n",
    "\n",
    "############ MERGING WITH THE SALES AND SHOPS AND ITEMS/ITEM_CATEGORIES\n",
    "df_sales = sales_util.merge_items_sales_n_shops(df_sales)\n",
    "\n",
    "############ CREATING THE MONTHLY REVENUE\n",
    "df_sales['revenue'] = df_sales['item_cnt_day'] * df_sales['item_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Pipeine-1\n",
    "Cleaning, Imputation, Outliers, Merging, Features etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#1. test data frame, adding date_block_num and month\n",
    "df_test['date_block_num'] = 34\n",
    "df_test['month'] = 11\n",
    "\n",
    "############ REPLACING DUPLICATE SHOPS FROM SALES\n",
    "# based on the above, duplicating as follows\n",
    "df_sales['shop_id'].replace({0: 57, 1: 58, 11: 10, 40: 39}, inplace=True)\n",
    "\n",
    "#2. merging, just like the sales\n",
    "df_test = sales_util.merge_items_sales_n_shops(df_test)\n",
    "\n",
    "############ REPLACING DUPLICATE CATEGORY\n",
    "# duplicate category id\n",
    "df_test['item_category_id'].replace({8: 80, 27: 74, 75: 76}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Set Pipeine-2\n",
    "Advanced feature generation, monthly grouping, merge with the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shops.shop_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shops.groupby(['shop_cat']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shops['city'] = df_shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "df_shops['shop_cat'] = df_shops['shop_name'].str.split(' ').map(lambda x: x[1]).astype(str)\n",
    "df_shops.loc[df_shops.city == '!Якутск', 'city'] = 'Якутск'\n",
    "shop_category = ['ТК','ТРК','ТРЦ','ТЦ']\n",
    "df_shops.shop_cat = df_shops.shop_cat.apply(lambda x: x if (x in shop_category) else 'etc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shops['shop_cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shops.groupby(['city']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_shops[df_shops.shop_cat=='ТЦ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shops.shop_cat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.item_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items['name_1'], df_items['name_2'] = df_items['item_name'].str.split('[', 1).str\n",
    "df_items['name_1'], df_items['name_3'] = df_items['item_name'].str.split('(', 1).str\n",
    "\n",
    "\n",
    "df_items['name_2'] = df_items['name_2'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ').str.lower()\n",
    "df_items['name_3'] = df_items['name_3'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ').str.lower()\n",
    "df_items = df_items.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items[['item_name','name_1','name_2','name_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = Counter(' '.join(df_items['name_2'].values.tolist()).split(' ')).items()\n",
    "df1 = Counter(' '.join(df_items['name_2'].values).split(' ')).items()\n",
    "df1 = sorted(df1, key=itemgetter(1))\n",
    "df1 = pd.DataFrame(df1, columns=['feature', 'count'])\n",
    "df1.fillna(0)\n",
    "df1 = df1[(df1['feature'].str.len() > 1) & (df1['count'] > 200)]\n",
    "\n",
    "df2 = Counter(' '.join(df_items['name_3'].values).split(' ')).items()\n",
    "df2 = sorted(df2, key=itemgetter(1))\n",
    "df2 = pd.DataFrame(df2, columns=['feature', 'count'])\n",
    "df2.fillna(0)\n",
    "df2 = df2[(df2['feature'].str.len() > 1) & (df2['count'] > 200)]\n",
    "\n",
    "item_feature_set = pd.concat([df1,df2])\n",
    "item_feature_set = item_feature_set.drop_duplicates(subset=['feature']).reset_index(drop=True)\n",
    "\n",
    "def name_correction(x):\n",
    "    x = x.lower()\n",
    "    x = x.partition('[')[0]\n",
    "    x = x.partition('(')[0]\n",
    "    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x)\n",
    "    re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x)\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "df_items['item_name'] = df_items['item_name'] .apply(lambda x: name_correction(x))\n",
    "df_items.name_2 = df_items.name_2.apply(lambda x: x[:-1] if x!='0' else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items['type'] = df_items.name_2.apply(lambda x: x[0:8] if x.split(' ')[0] == 'xbox' else x.split(' ')[0])\n",
    "df_items.loc[(df_items.type == 'x360') | (df_items.type == 'xbox360'), 'type'] = 'xbox 360'\n",
    "df_items.loc[df_items.type == '', 'type'] = 'mac'\n",
    "df_items.type = df_items.type.apply(lambda x: x.replace(' ',''))\n",
    "\n",
    "df_items.loc[(df_items.type == 'pc') | (df_items.type == 'pс') | (df_items.type == 'рс'), 'type'] = 'pc'\n",
    "df_items.loc[(df_items.type == 'рs3'), 'type'] = 'ps3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items[df_items.type=='psp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sum = df_items.groupby('type', as_index=False).sum()\n",
    "\n",
    "#the sum of all item_category_ids under a particular type shoudl be greater than 200\n",
    "to_del_types = group_sum.loc[group_sum.item_category_id < 200].type.tolist() \n",
    "group_sum.loc[group_sum.item_category_id < 200] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_del_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.name_2 = df_items.type.apply(lambda x: 'etc' if x in to_del_types else x)\n",
    "df_items = df_items.drop(['type'], axis=1)\n",
    "df_items.groupby(['name_2']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items['name_2'] = LabelEncoder().fit_transform(df_items['name_2'])\n",
    "df_items['name_3'] = LabelEncoder().fit_transform(df_items['name_3'])\n",
    "df_items.drop(['item_name', 'name_1'], axis=1, inplace=True)\n",
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Counter(s).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
